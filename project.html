<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Light Theme</title>
<link href="css/singlePageTemplate.css" rel="stylesheet" type="text/css">
<!--The following script tag downloads a font from the Adobe Edge Web Fonts server for use within the web page. We recommend that you do not modify it.-->
<script>var __adobewebfontsappname__="dreamweaver"</script>
<script src="http://use.edgefonts.net/source-sans-pro:n2:default.js" type="text/javascript"></script>

</head>
<body>
<header> <a href="">
    <h4 class="logo">PROFILE</h4>
    </a>
    <nav>
      <ul>
        <li><a href="myprofile.html">HOME</a></li>
        <li><a href="about.html">PROFILE</a></li>
        <li> <a href="project.html">PROJECTS</a></li>
      </ul>
    </nav>
</header>

<section class="hero" id="hero">
<h2 class="hero_header">MOTION COMMAND<span class="light">HEADS UP DISPLAY: MCHUD</span></h2>
</section>


<footer>
    <article class="footer_column">
		
<style>

#myheader {
  background-color: #9AE822;
  color: white;
  border-image-outset: 2px Black;
  padding: 0px;
  margin: 0px;
  text-align: center;
  font-size: 26pt;
	
	}

#openingp {
	background-color: black;
	color: white;
	padding:15px;
	margin: 0px;
	text-align: center;
	font-size: 16pt;
	}
#aboutme {
	font-color: white;	
	}
	
</style>
<body style="background-color:whitesmoke;">	
<h1 id="myheader">PROJECT 1.</h1>
	

<p id="openingp">MOTION COMMAND HEADS UP DISPLAY: MCHUD;</p>
</body>
<h3>Project overview</h3>	
<p>My project MCHUD is a motion gesture and voice command control module and heads up display for use in automobiles. The idea is to give the pilot control over the peripherals in the cockpit without taking their focus from the path ahead. Being able to control audio, voice and visual parameters such as audio volume, recieving and making calls with motion gesture commands. The visual displays will be shown above the dash on a clear diplay to keep pilot peripheral vision on the road while interacting with the user interface.My project MCHUD is a motion gesture and voice command control module and heads up display for use in automobiles. The idea is to give the pilot control over the peripherals in the cockpit without taking their focus from the path ahead. Being able to control audio, voice and visual parameters such as audio volume, recieving and making calls with motion gesture commands. The visual displays will be shown above the dash on a clear diplay to keep pilot peripheral vision on the road while interacting with the user interface. The idea is to give the pilot control over the peripherals in the cockpit without taking their focus from the path ahead. Being able to control audio, voice and visual parameters such as audio volume, recieving and making calls with motion gesture commands. The visual displays will be shown above the dash on a clear diplay to keep pilot peripheral vision on the road while interacting with the user interface.</p>
<h3>Motivation</h3>
Using a TFT panel and programming a Raspberry PI module, I built a digital instrument cluster for my beloved Mitsubishi Lancer using a prewritten interface program I was able to acquire from a software developer on the net. The software had incredible potential but was limited and did not allow for custom parameters or the visual effects. This is where my interest in programming started but unfortunately, in Australia modifications to the instrument cluster cannot be made ADR compliant and lead to a vehicle defection. Sure enough, within a few weeks I was pulled over for a random police check and was ordered to take my car off the road. This put an end to my work on the digital instrument cluster but I believe with current and topics under research and development this project could become something that is not only fun and aesthetically pleasing but a useful tool to increase driver concentration and road safety. <h3>The MCHUD</h3>
Distractions while driving are the cause of many motor vehicle accidents and with the introduction of mobile technology the distractions are more prevalent than ever. In the digital age mobile devices have always become a part of our everyday life and the need the to be in contact with friends and colleagues is important to us all. So here lies the crux of the issue; how do we keep in contact while keeping our eyes focused on the road. Laws in Australia vary state to state but in Queensland we cannot touch our mobile devices, stereo or any peripheral device that has buttons. So what if we could take calls, respond to texts and operate our car stereo and input into maps with hand gestures and voice commands. My idea for a 3D sensor array for motion control which allows the user to answer a call with the wave of your hand or a driectional point of a finger, change songs with the swipe of your hand and control your entire onboard computer with motion and voice controls. With a visible display HUD on top of the dash which when not in use is clear and completely see through not obscuring view of the pilot in the vehicle.
On the HUD the user can display music, view phone contacts or even have the display set up for tacho or for the auto enthusiast or racing driver features such as lap times, max speed, tire pressure, temp, the list goes on. 
With so many applications the user would have control over what is shown and when as well as full customization of the visual display shown with connectivity via Bluetooth or USB users could have access to an open source library of control interfaces and graphics suited to the needs of the pilot.
		</p>
<h3>Tools and technology</h3>
3d motion sensor technology is become precise and relatively inexpensive being used in everything from animation in the film industry and gaming to aviation and terrain mapping. This project would require a motion sensor array capable of picking up specific hand gestures with high accuracy and this technology already exists.<br>
The transperant HUD would consist of an in glass display such as the Lumineq IGLD. Building on this technology to create a full color, high resolution display. 
<br>
The module could consist of a powerful version of a Raspberry PI and the software could be derived from that which is implemented to use the xBox Kinect or something of that nature.<br>

</P>
<h3>References</h3>
<p>https://www.lumineq.com/products/in-glass-laminated-displays
<br>https://www.raspberrypi.org/<br>https://developer.microsoft.com/en-us/windows/kinect/
</p>
</body>
</html>
